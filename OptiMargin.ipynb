{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from scipy import optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas numpy scikit-learn pymc arviz scipy matplotlib seaborn openpyxl ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             DateTime       Date ProductID   Cost   Price  MarginPercent  \\\n",
      "0 2019-09-04 19:03:51 2019-09-04    459238  67.73  309.99       0.321849   \n",
      "1 2019-09-04 19:06:46 2019-09-04    350105   0.98    3.96       0.292929   \n",
      "2 2019-09-04 19:06:57 2019-09-04    350275   0.49    2.29       0.327511   \n",
      "3 2019-09-04 19:07:49 2019-09-04  467960_1  10.75   42.99       0.290300   \n",
      "4 2019-09-04 19:08:01 2019-09-04    418550   3.12   14.99       0.332221   \n",
      "\n",
      "          Brand                  Category  VisitorReturning VisitorSource  \\\n",
      "0  Wisch-Star¬Æ          Hygienebereiche                  0        Google   \n",
      "1       Antikal          Hygienebereiche                  0        Google   \n",
      "2  Dr. Beckmann          Hygienebereiche                  0        Anders   \n",
      "3  Wisch-Star¬Æ          Reinigungswagen                  1        Anders   \n",
      "4  Wisch-Star¬Æ  Wischmop & Bodenwischer                  0        Google   \n",
      "\n",
      "  VisitorOS  BasketCount  PurchaseCount  Margin  Reward  \n",
      "0   Android            0              0   99.77     0.0  \n",
      "1   Android            0              0    1.16     0.0  \n",
      "2    Mac OS            0              0    0.75     0.0  \n",
      "3   Android            0              0   12.48     0.0  \n",
      "4   Android            0              0    4.98     0.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175630 entries, 0 to 175629\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   DateTime          175630 non-null  datetime64[ns]\n",
      " 1   Date              175630 non-null  datetime64[ns]\n",
      " 2   ProductID         175630 non-null  object        \n",
      " 3   Cost              175630 non-null  float64       \n",
      " 4   Price             175630 non-null  float64       \n",
      " 5   MarginPercent     175630 non-null  float64       \n",
      " 6   Brand             175586 non-null  object        \n",
      " 7   Category          175608 non-null  object        \n",
      " 8   VisitorReturning  175630 non-null  int64         \n",
      " 9   VisitorSource     175630 non-null  object        \n",
      " 10  VisitorOS         175630 non-null  object        \n",
      " 11  BasketCount       175630 non-null  int64         \n",
      " 12  PurchaseCount     175630 non-null  int64         \n",
      " 13  Margin            175630 non-null  float64       \n",
      " 14  Reward            175630 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(5), int64(3), object(5)\n",
      "memory usage: 20.1+ MB\n",
      "None\n",
      "Training data shape: (1420, 702)\n",
      "Test data shape: (355, 702)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/OptiMargin/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [0, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load dataset (assuming it's the full Excel file)\n",
    "data = pd.read_excel(\"Dataset Price optimization RL.xlsx\")\n",
    "\n",
    "# Rename columns for consistency\n",
    "data.columns = ['DateTime', 'Date', 'ProductID', 'Cost', 'Price', 'MarginPercent', 'Brand',\n",
    "                'Category', 'VisitorReturning', 'VisitorSource', 'VisitorOS', 'BasketCount',\n",
    "                'PurchaseCount', 'Margin', 'Reward']\n",
    "\n",
    "# Convert DateTime and Date to datetime for consistency\n",
    "data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Check data\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "\n",
    "# Define features and target\n",
    "categorical_features = ['Brand', 'Category', 'VisitorSource', 'VisitorOS', 'VisitorReturning']\n",
    "numerical_features = ['Price', 'MarginPercent']\n",
    "target = 'PurchaseCount'  # Use PurchaseCount > 0 as binary target for simplicity\n",
    "\n",
    "# Create binary target (1 if purchased, 0 if not)\n",
    "data['Purchased'] = (data['PurchaseCount'] > 0).astype(int)\n",
    "\n",
    "# Handle missing values (if any)\n",
    "data = data.dropna()\n",
    "\n",
    "# Aggregate data by ProductID to get average behavior (optional for sparse data)\n",
    "product_data = data.groupby('ProductID').agg({\n",
    "    'Price': 'mean', 'MarginPercent': 'mean', 'Purchased': 'mean', 'BasketCount': 'mean',\n",
    "    'PurchaseCount': 'mean', 'Brand': 'first', 'Category': 'first', 'VisitorSource': 'first',\n",
    "    'VisitorOS': 'first', 'VisitorReturning': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Split features and target\n",
    "X = product_data[categorical_features + numerical_features]\n",
    "y = product_data['Purchased']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline with handle_unknown='ignore' to avoid errors with unseen categories\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'),\n",
    "         categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit and transform\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "feature_names = (numerical_features +\n",
    "                 preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features).tolist())\n",
    "\n",
    "# Print shapes for verification\n",
    "print(\"Training data shape:\", X_train_processed.shape)\n",
    "print(\"Test data shape:\", X_test_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "/home/ubuntu/OptiMargin/.venv/lib/python3.10/site-packages/pytensor/link/c/cmodule.py:2959: UserWarning: PyTensor could not link to a BLAS installation. Operations that might benefit from BLAS will be severely degraded.\n",
      "This usually happens when PyTensor is installed via pip. We recommend it be installed via conda/mamba/pixi instead.\n",
      "Alternatively, you can use an experimental backend such as Numba or JAX that perform their own BLAS optimizations, by setting `pytensor.config.mode == 'NUMBA'` or passing `mode='NUMBA'` when compiling a PyTensor function.\n",
      "For more options and details see https://pytensor.readthedocs.io/en/latest/troubleshooting.html#how-do-i-configure-test-my-blas-library\n",
      "  warnings.warn(\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [intercept, beta_price, beta_margin, brand_mu, category_mu, beta_other]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06a874ec4894872870af4a579413b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "\n",
    "# Convert to numpy arrays if not already done\n",
    "X_train_np = np.array(X_train_processed)\n",
    "X_test_np = np.array(X_test_processed)\n",
    "y_train_np = np.array(y_train)\n",
    "\n",
    "# Bayesian model with hierarchical grouping by Brand and Category\n",
    "with pm.Model() as model:\n",
    "    # Get indices for hierarchical grouping (using original X_train for Brand and Category)\n",
    "    brand_idx = X_train['Brand'].astype('category').cat.codes.values\n",
    "    category_idx = X_train['Category'].astype('category').cat.codes.values\n",
    "    n_brands = len(np.unique(brand_idx))\n",
    "    n_categories = len(np.unique(category_idx))\n",
    "\n",
    "    # Priors\n",
    "    intercept = pm.Normal('intercept', mu=0, sigma=10)\n",
    "    beta_price = pm.Normal('beta_price', mu=0, sigma=10)\n",
    "    beta_margin = pm.Normal('beta_margin', mu=0, sigma=10)\n",
    "\n",
    "    # Hierarchical effects\n",
    "    brand_mu = pm.Normal('brand_mu', mu=0, sigma=1, shape=n_brands)\n",
    "    category_mu = pm.Normal('category_mu', mu=0, sigma=1, shape=n_categories)\n",
    "\n",
    "    # Coefficients for other categorical features (after Price and MarginPercent)\n",
    "    n_other_features = X_train_np.shape[1] - 2  # Subtract Price and MarginPercent\n",
    "    beta_other = pm.Normal('beta_other', mu=0, sigma=10, shape=n_other_features)\n",
    "\n",
    "    # Linear combination\n",
    "    logits = (intercept +\n",
    "              beta_price * X_train_np[:, feature_names.index('Price')] +\n",
    "              beta_margin * X_train_np[:, feature_names.index('MarginPercent')] +\n",
    "              brand_mu[brand_idx] + category_mu[category_idx] +\n",
    "              pm.math.dot(X_train_np[:, 2:], beta_other))\n",
    "\n",
    "    # Likelihood\n",
    "    likelihood = pm.Bernoulli('likelihood', logit_p=logits, observed=y_train_np)\n",
    "\n",
    "    # Sample from posterior\n",
    "    trace = pm.sample(2000, tune=1000, return_inferencedata=True, random_seed=42)\n",
    "\n",
    "# Summarize results\n",
    "print(az.summary(trace, hdi_prob=0.95))\n",
    "az.plot_trace(trace)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
